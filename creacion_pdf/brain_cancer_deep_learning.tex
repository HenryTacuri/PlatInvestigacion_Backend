% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
\titlerunning{Universidad Politecnica Salesiana}

%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%รยบ
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%
\usepackage{hyperref}
\usepackage{float}
\usepackage{multirow}
\usepackage{cite}
\usepackage{breqn}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{textcomp}
\usepackage{subfigure}
\usepackage{soul}
\usepackage[utf8]{inputenc}
\usepackage{tabularx} % Importa el paquete
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb} 
\usepackage{array}
\usepackage{algpseudocode}
\usepackage{blindtext}
\usepackage{color}
\usepackage{algorithm}
\usepackage{epstopdf}
\usepackage{placeins}
\usepackage{wrapfig}
\usepackage{graphicx} % Necesario para \includegraphics
\usepackage{enumitem}

\restylefloat{algorithm}
\newcommand{\INDSTATE}[1][1]{\STATE\hspace{#1\algorithmicindent}}
\newcounter{mytempeqncnt}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
		T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
	
\begin{document}
%
\title{Survey of Brain Cancer Deep Learning}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Remigio Hurtado\inst{1}}
%
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Universidad Polit\'ecnica Salesiana, Calle Vieja 12-30 y Elia Liut, Cuenca, Ecuador. \email{rhurtadoo@ups.edu.ec}\\
\url{ups.edu.ec}}
%
\maketitle    
%
\begin{abstract}
Recent advancements in deep learning techniques have significantly transformed the diagnosis and treatment planning of brain tumors. This article presents a comprehensive survey of deep learning applications in brain cancer detection, emphasizing innovative models and methodologies that enhance diagnostic accuracy and patient outcomes. Our methodology employs a machine learning	extendash{}based approach to identify the most relevant papers, highlighting recent and highly cited studies in the field. Notably, we introduce the FT	extendash{}FEDTL model, which dramatically improves brain tumor classification accuracy using microwave imaging data. We also discuss the limited integration of machine learning within glioblastoma research, underscoring the need for clearer methodologies and comprehensive data usage. Furthermore, we present a novel model that classifies gliomas directly from magnetic resonance spectroscopic imaging (MRSI) data, thus improving diagnostic efficiency by bypassing traditional preprocessing requirements. The SLCA	extendash{}UNet architecture is showcased for its ability to enhance brain tumor segmentation, combining advanced techniques that improve accuracy while reducing processing time. Additionally, the survey explores how deep learning is transforming cancer detection across various types by automating the analysis of medical images. Finally, we emphasize the importance of feature extraction through deep learning, bridging genomic and histopathological data to foster a better understanding of disease mechanisms and personalized medicine. Overall, the integration of artificial intelligence in medical imaging presents a pivotal opportunity to advance early cancer detection and improve patient outcomes.
\end{abstract}

\begin{keywords}
brain cancer, deep learning, microwave imaging, tumor classification, medical imaging
\end{keywords}

\section{Introduction}
The rapid advancement in deep learning technologies has profoundly impacted the field of brain cancer diagnosis, particularly in improving the accuracy of tumor classification and enhancing treatment planning. As the incidence of brain cancer continues to rise globally, the need for early detection methods has grown increasingly critical. Traditional imaging techniques like MRI and CT scans, while valuable, often come with limitations, including high costs and exposure to ionizing radiation. In contrast, microwave brain imaging (MBI) has emerged as a promising alternative, offering a non	extendash{}invasive approach devoid of harmful radiation, yet accurately classifying tumors from MBI images remains a significant challenge due to the time	extendash{}consuming nature of manual analysis and variability among radiologists \cite{Hossain_2024}.

To tackle these challenges, innovative deep learning models have been developed, such as the FT	extendash{}FEDTL model, which utilizes the InceptionV3 architecture for feature extraction while incorporating fine	extendash{}tuned layers to optimize classification performance. The model demonstrates remarkable accuracy, achieving up to 99.65%, thereby significantly outperforming traditional methods \cite{Hossain_2024}. By leveraging a balanced dataset of 4200 images, the FT	extendash{}FEDTL model highlights the potential of deep learning in revolutionizing brain tumor classification.

Despite these advancements, a gap remains in the effective application of machine learning techniques in glioblastoma research. A systematic review identified 54 studies predominantly focused on integrating histopathological data with genomic information. While this integration is essential for improving diagnostic accuracy, many studies suffer from insufficient methodological clarity, which hampers reproducibility and robustness in findings \cite{Chun_2025}. Addressing these gaps is vital for advancing the field and ensuring that deep learning models can provide reliable insights into tumor pathology.

Moreover, the integration of magnetic resonance spectroscopic imaging (MRSI) with deep learning methodologies presents another avenue for enhancing glioma classification. Recent studies propose novel models that process raw MRSI data directly, achieving commendable accuracy in classifying gliomas and healthy tissues. This approach minimizes traditional preprocessing requirements and highlights the model's ability to generalize across diverse datasets, thereby streamlining diagnostic processes \cite{Erin_2025}.

In the realm of tumor segmentation, the SLCA	extendash{}UNet architecture has been introduced to overcome limitations of conventional models. By incorporating advanced techniques such as residual dense blocks and attention mechanisms, SLCA	extendash{}UNet enhances segmentation accuracy and reduces processing time, thus representing a significant advancement in biomedical image analysis \cite{P.S._2025}. Evaluations on benchmark datasets indicate that this model achieves a Dice Similarity Coefficient of 0.921, underscoring its effectiveness compared to existing methods.

In conclusion, the confluence of deep learning and medical imaging technologies holds immense promise for the future of brain cancer detection and treatment. By systematically integrating various data types and refining methodologies, researchers can enhance diagnostic capabilities and ultimately improve patient outcomes. The ongoing evolution in this field emphasizes the importance of developing robust, interpretable models that can seamlessly transition into clinical applications, paving the way for a new era in oncology driven by advanced computational techniques. Future work should focus on validating these models in clinical settings, ensuring their applicability across diverse demographics, and addressing ethical considerations surrounding patient data usage \cite{Hossain_2024}.

The key contributions of our study can be summarized as follows: 

\begin{itemize}
    \item \textbf{Comprehensive Review of the State of the Art}: Detailed analysis and synthesis of the most relevant and recent contributions in the existing literature.
    \item \textbf{Structured Methodology Based on CRISP	extendash{}DM}: Application of a standard methodology to guide the data mining process, including phases from understanding the problem to generating knowledge representations.
    \item \textbf{Advanced Machine Learning Models}: Use of Latent Dirichlet Allocation (LDA) to identify and categorize latent topics and development of a recommendation system based on the document	extendash{}topic matrix, in order to identify the most relevant themes and the most important associated documents.
    \item \textbf{Synthetized Knowledge Generation}: Creation of textual summaries and visualization of relationships between topics and documents to enhance understanding.
    \item \textbf{Comprehensive and Understandable Reports}: Integration of representations in detailed reports that combine text and figures to provide a clear and complete overview of the analysis.
\end{itemize}

In the remainder of the document, the following is presented: The development methodology of this study, then, the evaluation in the field, the topics: Deep Learning Glioma, SLCA	extendash{}UNet Advancement, Deep Learning Oncology, Deep Learning Integration,  subsequently, the trends in Brain Cancer Deep Learning, related works and original contributions, and finally, the conclusions.
\section{Methodology}

Our methodology is designed to ensure a comprehensive and systematic analysis of scientific literature. The methodology used in this study builds on our previous work, including a methodology that leverages machine learning and natural language processing techniques \cite{Hurtado2023}, and a novel method for predicting the importance of scientific articles on topics of interest using natural language processing and recurrent neural networks \cite{Lopez2024}. The process is structured into three phases: data preparation, topic modeling, and the generation and integration of knowledge representations. Each phase is essential for transforming raw text data into meaningful insights, and the detailed parameters and algorithm are explained below. The table \ref{tabDescription} describes the parameters for understanding the overall process and algorithm. The high-level process is presented in Fig. \ref{fig:Methodology}, and the detailed algorithm is outlined in Table \ref{tab:Algorithm}.\\ 

In the data preparation phase, we focus on extracting and cleaning text from scientific documents using natural language processing (NLP) techniques. This phase involves several steps to ensure that the text data is ready for analysis. First, text is extracted from the documents, and non-alphabetic characters that do not add value to the analysis are removed. Next, the text is converted to lowercase, and stopwords (common words that do not contribute much meaning) are removed. We then apply lemmatization, which transforms words to their base form (e.g., "running" becomes "run"). Each document is tokenized (split into individual words or terms), and n-grams (combinations of words) are identified to find common terms. We generate a unified set of common terms, denoted as $TE$, which includes both the terms extracted from the documents and basic terms relevant to any field of study, such as [Fundamentals, Evaluation of Solutions, Trends]. Finally, each document is vectorized with respect to $TE$, resulting in the Document-Term Matrix (DTM).\\

The DTM is a crucial component for topic modeling. It is a matrix where the rows represent the documents in the corpus, and the columns represent the terms (words or n-grams) extracted from the corpus. Each cell in the matrix contains a value indicating the presence or frequency of a term in a document. This structured representation of the text data allows us to apply machine learning techniques to uncover hidden patterns.\\

In the topic modeling phase, we use Latent Dirichlet Allocation (LDA), a popular machine learning technique for identifying topics within a set of documents. By applying LDA to the DTM, we transform the matrix into a space of topics. Specifically, LDA provides us with two key matrices: the Topic-Term Matrix ($\beta$) and the Document-Topic Matrix ($\theta$). The Topic-Term Matrix ($\beta$) indicates the probability that a term is associated with a specific topic, while the Document-Topic Matrix ($\theta$) indicates the probability that a document belongs to a specific topic.

To enhance this approach, we integrate predefined topic representations and refine document-topic assignments. In addition to extracting topics purely from the document-term matrix (DTM), we incorporate a set of predefined topics, namely [Fundamentals, Evaluation of Solutions, Trends], which are represented using a predefined set of keywords generated by a language generation model. This ensures that the model captures both the inherent structure of the dataset and domain-relevant themes. The predefined topics are processed through a keyword extraction function, which selects the most relevant words associated with each topic based on the provided corpus.

To construct a more robust topic representation, we create predefined topic matrices that integrate predefined topic vectors with the most relevant keywords extracted for each topic. These matrices are then normalized and combined with the LDA-generated topic distribution, ensuring a refined alignment of document-topic assignments. By doing so, we mitigate the limitations of purely unsupervised topic modeling, which might generate topics that lack semantic clarity.

Finally, to improve interpretability, we assign meaningful names to the discovered topics by combining the highest-probability terms from the topic-term matrix ($\beta$). Using a language generation model, we generate concise and descriptive topic names, ensuring that each topic is easily understandable. This process results in a refined set of topics ($T$), the most relevant terms ($K$), and a topic-term graph ($G_{tk}$) that illustrates relationships between topics and key terms. This methodology enhances the effectiveness of topic modeling by integrating both machine learning and domain-specific knowledge, leading to a more structured and meaningful representation of the analyzed corpus.

The final phase involves the generation and integration of knowledge representations, which include summaries, keywords, and interactive visualizations. For each topic $t$ in $T$, we identify the $N$ most relevant documentsรขโฌโthose with the highest probabilities in $\theta$. This set, $D_t$, represents the documents most closely related to each topic. We then generate summaries of these documents, each with a maximum of $W_b$ words, using a language generation model. These summaries include references to the most relevant documents, which are added to the set $R_d$ if they are not already included. We also integrate all the summaries and generate $J$ suggested keywords using a language generation model. Additionally, we create interactive graphs from the $G_{tk}$ graph, showcasing nodes and relationships between the topics and terms, and highlighting significant connections.We also integrate all the summaries and generate $J$ suggested keywords using a language generation model. Additionally, the topic titles were improved based on the generated summaries using a language generation model, ensuring that the final topic names more accurately reflect the summarized content.
\\

This methodology provides a clear, structured approach to analyzing scientific literature, leveraging advanced NLP and machine learning techniques to generate useful and comprehensible knowledge representations. This is the methodology used in the development of this study, which presents the fundamentals, solution evaluation techniques, trends, and other topics of interest within this field of study. This structured approach ensures a thorough review and synthesis of the current state of knowledge, providing valuable insights and a solid foundation for future research.

\begin{table*}[!h]
	\caption{\centering Description of parameters of the proposed methodology}
	\resizebox{\textwidth}{!}{ % Ajusta el ancho de la tabla al texto
		\begin{tabular}{|l|l|}
			\hline
			\textbf{Parameter} & \textbf{Description}                                                            \\ \hline
			$T$                  & Set of topics to be generated with the LDA model. \\ \hline
			$\#T$                & Cardinality of $T$. That is, the number of topics (dimensions).                                    \\ \hline
			$K$                  & Set of common terms with the highest probability in topic $t$ used to label that topic. \\ \hline
			$\#K$ 				 & Cardinality of $K$.                                         \\ \hline
			$W_{t}$   			 & Maximum number of words for combining the common terms of topic $t$ into a new topic name.\\ \hline
			$N$                  & Number of the most relevant documents to generate a summary of topic $t$.\\ \hline
			$W_b$                & Maximum number of words to generate a summary of the list of $N$ most related documents to topic $t$.\\ \hline
			$J$                  & Number of suggested keywords to be generated as knowledge representation.\\ \hline
			$W_k$ 				 & Number of keywords selected by language generation model from the LDA-generated words to construct the predefined matrix. \\ \hline
		\end{tabular}
	}
	\label{tabDescription}
\end{table*}


\begin{figure*}[!h]
	\centering
	\includegraphics[width=1.0\textwidth]{Figures/method.png}
	\caption{Methodology for the generation of knowledge representations}
	\label{fig:Methodology}
\end{figure*}

%Actual
\begin{figure*}[!h]
	\centering
	\resizebox{\textwidth}{!}{ % Ajusta el ancho de la tabla a \textwidth
		\begin{tabular}{l}
			\hline
			\textbf{General Algorithm} \\
			\hline
			\textbf{Input:} Field of study, Scientific articles collected from virtual libraries, $\#T$, $\#K$, $W_{t}$, $N$, $W_b$, $J$, $W_k$\\
			\hline
			\textbf{Phase 1: Data Preparation with Natural Language Processing (NLP)} \\
			\quad a. Extract of text from documents. \\
			\quad b. Remove non-alphabetic characters that do not add value to the analysis. \\
			\quad c. Convert to lowercase and remove stopwords. \\
			\quad d. Apply lemmatization to transform words to their base form. \\
			\quad e. In each document, tokenize and identify n-grams to identify common terms (words or n-grams). \\
			\quad f. Unified generation of common terms of all documents. Where $TE$ is the unified set of common terms.\\
			\quad g. Add in $TE$ the basic terms for any field of study, such as: [Fundamentals, Evaluation of Solutions, Trends]. \\
			\quad h. Vectorize each document with respect to $TE$ and generate Document-Term Matrix (DTM).\\
			\quad \textbf{Output:} For each document [title, original text, common terms], and Document-Term Matrix (DTM)\\
			\textbf{Phase 2: Topic Modeling whit Machine Learning} \\
			\quad \textbf{Input:} Document-Term Matrix (DTM) \\
			\quad a. Apply Latent Dirichlet Allocation (LDA) to transform the DTM Matrix into a space of $\#T$ topics (dimensions).\\
			\quad b. Obtain the Topic-Term Matrix ($\beta$) that indicates the probability that a term is generated by a specific topic.\\ 
			\quad c. Obtain the Document-Topic Matrix ($\theta$) that indicates the probability that a document belongs to a specific topic.\\
			\quad d. Generate predefined topic representations using language generation model by sending the LDA-generated words and selecting $W_k$ keywords for each predefined topic.\\
			\quad e. Construct predefined matrices by combining predefined topic vectors with the $W_k$ selected keywords.\\
			\quad f. Normalize and combine the predefined matrices with the LDA-generated topic distribution to refine document-topic assignments, resulting in the new Matrix ($\beta$).\\
			\quad g. For each unknown $t$ topic in $\beta$, assign a name or label to the $t$ topic by combining the $\#K$ highest probability\\
			\quad \quad common terms in $\beta$ associated with that $t$ topic. This generates: \\
			\quad \quad The $T$ Set with the $\#T$ most relevant topics. \\
			\quad \quad The $K$ Set with the $\#K$ most relevant terms. \\
			\quad \quad The $G_{tk}$ Graph of the relationships between the most relevant topics ($T$) and the most relevant terms ($K$). \\
			\quad h. For each topic $t$ in $T$, modify topic $t$ by combining the common terms of $t$ into a new topic name with at most \\
			\quad \quad $W_{t}$ words using a language generation model.\\
			\quad \textbf{Output:} Relevant Topics ($T$), Topic-Term Matrix ($\beta$), Document-Topic Matrix ($\theta$) \\
			\textbf{Phase 3: Generation and Integration of Knowledge Representations} \\
			\quad \textbf{Input:} Relevant Topics $T$, Document-Topic Matrix ($\theta$) \\
			\quad \textbf{3.1: Knowledge representations through summaries and keywords}\\
			\quad \quad a. For each $t$ topic in $T$, obtain its $N$ most relevant documents, i.e., those with the highest probabilities in $\theta$. \\
			\quad \quad \quad Thus, $D_t$ represents the set of documents most related to each topic $t$.\\
			\quad \quad b. For each topic $t$ in $T$, and from $D_t$ generate a summary of the list of documents most related to that topic $t$ with \\
			\quad \quad \quad at most $W_b$ words using a language generation model. \\
			\quad \quad c. Incorporate into the summary the text citing references to the most relevant documents. Add these references to the \\ 
			\quad \quad \quad set $R_d$, which will contain all cited references, including new references if they have not been previously included.\\
			\quad \quad d. Integrate all the summaries and from them generate $J$ suggested keywords using a language generation model.\\
			\quad \quad e. Improve topic titles with a language generation model.\\
			\quad \textbf{3.2: Knowledge representations through knowledge visualizations with interactive graphs}\\
			\quad \quad a. From the $G_{tk}$ graph, generate an interactive graph with nodes and relationships between the topics $T$\\
			\quad \quad and the $K$ most relevant terms.\\
			\quad \quad b. Highlight the connections between the topics $T$ and the $K$ most relevant terms.\\
			\quad \textbf{3.3: Integration of Knowledge Representations}\\
			\hline
			\textbf{Output:} Knowledge Representations \\
			\hline
		\end{tabular}
	}
	\caption{\centering General algorithm of the methodology incorporating natural language processing, machine learning techniques and language generation models}
	\label{tab:Algorithm}
\end{figure*}

\FloatBarrier


\section{Fundamental of brain cancer deep learning}
The early detection of brain tumors is critical for effective treatment and improved patient outcomes, given the rising incidence of brain cancer globally. Traditional imaging methods such as MRI and CT scans, while effective, have limitations including high costs and exposure to ionizing radiation. In recent years, microwave brain imaging (MBI) has emerged as a promising alternative due to its non-invasive nature and lack of harmful radiation, making it suitable for early diagnosis. However, the challenge of accurately classifying tumors from MBI images remains, as manual analysis is time-consuming and prone to variability among radiologists \cite{Hossain_2024}.

To address these challenges, a deep transfer learning model known as FT-FEDTL has been proposed. This model leverages the InceptionV3 architecture for feature extraction while incorporating fine-tuned layers to enhance classification performance. The model is designed to classify tumors into six categories: Normal (NT), Single Benign Tumor (SBT), Single Malignant Tumor (SMT), Two Benign Tumors (TBT), Two Malignant Tumors (TMT), and Single Benign and Single Malignant Tumor (SBSMT). By utilizing a balanced dataset of 4200 images, the FT-FEDTL model demonstrated high accuracy, achieving 99.65% accuracy, 99.16% recall, and 99.23% F-score, significantly outperforming traditional models and other pretrained architectures in the classification tasks \cite{Hossain_2024}.

The experimental setup involved a thorough preprocessing phase, including data augmentation techniques to enhance the training dataset. This augmentation was essential for balancing the dataset, ensuring that classes were adequately represented, which is crucial for effective machine learning outcomes. The FT-FEDTL model also employs various hyperparameter tuning strategies to optimize performance during training. The findings suggest that the model's architecture and the methodologies employed in feature extraction and classification provide a robust framework for accurately identifying brain tumors from MBI images \cite{Hossain_2024}.

In conclusion, the FT-FEDTL model represents a significant advancement in the field of medical imaging and brain tumor classification. Its integration of deep learning techniques with microwave imaging has the potential to revolutionize the diagnosis of brain tumors, offering a reliable tool for radiologists and medical professionals. Future work should focus on validating this model in clinical settings, exploring its applicability across different demographics, and addressing ethical considerations related to patient data usage \cite{Hossain_2024}.
\begin{figure}[h]
\centering
\includegraphics[width=1\textwidth]{Figures/lda_topic_graph_simplified.png}
\caption{Grafo de relaciones temรกticas generado mediante LDA, donde los nodos representan temas identificados y sus palabras clave asociadas. La palabra clave central conecta los temas, y las palabras compartidas aparecen enlazadas a mรบltiples etiquetas segรบn su relevancia en el modelo. Los pesos de los enlaces reflejan la importancia de cada tรฉrmino dentro de su tรณpico.}
\end{figure}
\section{Evaluation of brain cancer deep learning}
Recent advancements in machine learning (ML) and deep learning (DL) have significantly influenced the field of brain tumor research, particularly in glioblastoma (GBM) histopathology. This systematic review aims to analyze how ML/DL techniques have been applied to understand GBM's complex pathology by integrating histopathological data with various -omics datasets. Despite the potential of ML/DL to unravel intricate biological relationships, only a limited number of studies have effectively utilized these methods in the context of GBM histopathology, highlighting a gap in current research. 

The review identifies 54 relevant studies, predominantly focusing on GBM, and categorizes them based on their methodologies, types of data used, and outcomes. The findings suggest that many studies have employed histopathological images in conjunction with genomic data to enhance diagnostic accuracy and prognostic predictions. For instance, several studies utilized SVM and ResNet-based CNN architectures, which have shown promise in classifying tumor subtypes and predicting patient outcomes based on histological features. However, a notable issue is that many studies lack clarity in reporting their training and evaluation methodologies, which hampers reproducibility and robustness in their findings \cite{Chun_2025}.

The review further emphasizes the heterogeneity of GBM, underscoring the importance of integrating various data types to provide comprehensive insights into tumor behavior. While there is a growing trend of using ML/DL approaches, the majority of existing studies still primarily focus on classification and segmentation tasks without leveraging the potential of bioinformatics data to offer deeper biological insights into GBM pathology. Therefore, the authors recommend that future studies should aim to systematically integrate histopathological data with biological information to enhance the understanding of GBM and improve clinical decision-making processes \cite{Chun_2025}.

Moreover, the literature indicates that while there is a clear interest in utilizing ML/DL techniques, the effectiveness of these models can be influenced by the quality and diversity of the datasets used. The review calls for more rigorous standards in reporting the origins and characteristics of datasets, as well as employing robust cross-validation techniques to ensure the generalizability of the models developed \cite{Amran_2024}. 

In conclusion, the integration of ML/DL in GBM histopathological studies is still in its early stages, with significant opportunities for future research to bridge the gap between computational methods and clinical applicability. By enhancing the synergy between histological analysis and bioinformatics, researchers can pave the way for more personalized treatment strategies for patients suffering from GBM.
\section{Deep learning glioma}
In the pursuit of effective glioma treatment, the classification of brain tumors has emerged as a critical area of research. Traditional imaging techniques like magnetic resonance imaging (MRI) often fall short in accuracy and efficiency, particularly in distinguishing gliomas. In contrast, magnetic resonance spectroscopic imaging (MRSI) offers detailed insights into the chemical composition of tissues, enhancing diagnostic capabilities. However, MRSI faces significant challenges, including low signal-to-noise ratios and complex data analysis, which necessitate advanced methodologies to improve its implementation and clinical utility \cite{Erin_2025}.

Recent advances in deep learning have shown promise in various medical imaging applications, including the classification of brain tumors. Convolutional neural networks (CNNs) have successfully been employed to autonomously learn features from MRSI data, which could streamline analysis processes and improve diagnostic accuracy \cite{Erin_2025}. This study proposes a novel deep learning model that processes raw MRSI data directly, bypassing traditional preprocessing requirements. By leveraging synthetic and phantom-generated spectra, the model demonstrates the capacity to classify voxels containing gliomas from healthy tissues based on time-domain MR signals \cite{Erin_2025}.

The proposed model consists of two main components: a CNN for transforming time-domain signals into frequency-domain spectra and a DenseNet for classifying these spectra as glioma or healthy tissue. This architecture not only minimizes processing time but also enhances the model's ability to generalize across different datasets. With a training dataset comprising 20,000 MR spectra, the model achieved a commendable area under the curve (AUC) of 0.95, indicating its effectiveness in differentiating glioma from healthy tissues \cite{Erin_2025}.

The study further implements Grad-CAM (Gradient-weighted Class Activation Mapping) to visualize the model's decision-making process, highlighting key spectral regions that contribute to classifications. The model primarily emphasizes the choline peak for glioma evaluation, while healthy tissue assessments focus on the N-acetyl-aspartate (NAA) region, reflecting known biochemical markers associated with brain tumors \cite{Erin_2025}. This approach not only showcases the model's interpretability but also its potential clinical applications in enhancing glioma diagnosis.

In conclusion, this research underscores the potential of integrating MRSI with deep learning methodologies to improve the classification of gliomas. The model's ability to operate directly on raw data highlights a significant step towards making advanced imaging techniques more accessible and efficient in clinical settings. Future work will aim to validate the model across larger, multi-center datasets and refine its application in distinguishing between different glioma subtypes, thereby enhancing its clinical relevance and utility \cite{Erin_2025}.
\section{Slca-unet advancement}
The detection and segmentation of brain tumors from MRI images are crucial for effective diagnosis and treatment planning. Traditional methods of manual segmentation are time-consuming and prone to variability, which highlights the need for automated solutions. Recent advancements in deep learning, particularly with architectures like UNet, have shown promise in automating this process. However, conventional UNet models often struggle with accuracy and contextual information processing due to their complexity. 

To address these limitations, a novel architecture named SLCA-UNet has been proposed. This model integrates residual dense blocks, layered attention mechanisms, and channel attention modules, enabling it to capture both wide and thin features more effectively than prior models. By leveraging these enhancements, SLCA-UNet aims to improve segmentation accuracy while reducing processing time, making it a significant advancement in the field of biomedical image analysis \cite{P.S._2025}.

The SLCA-UNet architecture enhances the UNet framework by incorporating various innovative components. The use of residual dense blocks facilitates better feature extraction and gradient flow, thereby overcoming the vanishing gradient problem often encountered in deep networks \cite{P.S._2025}. Furthermore, the inclusion of attention mechanisms allows the model to focus on the most informative features, which is particularly beneficial in distinguishing tumor tissues from healthy brain tissues. This approach not only enhances the model's performance but also reduces the overall computational complexity, making it feasible for real-time applications \cite{P.S._2025}.

Evaluations conducted on benchmark datasets such as BraTS 2017, 2018, and 2019 demonstrate the effectiveness of the SLCA-UNet model. The results indicate that the architecture achieves a Dice Similarity Coefficient (DSC) of 0.921 for whole tumor segmentation, outperforming several state-of-the-art methods. This improvement is significant, as it directly correlates with better clinical outcomes through more precise tumor delineation, which is vital for treatment planning and monitoring \cite{P.S._2025}.

In conclusion, the SLCA-UNet model represents a substantial leap forward in automatic brain tumor segmentation. By addressing the limitations of traditional UNet architectures and incorporating advanced techniques, it offers a reliable and efficient solution for medical imaging applications. Future work will focus on further refining the model and validating its performance in clinical settings, potentially enhancing the accuracy and speed of brain tumor diagnosis \cite{P.S._2025}.
\section{Deep learning oncology}
The advancement of deep learning techniques in medical imaging has revolutionized early cancer detection, providing significant improvements in diagnostic accuracy and efficiency. These techniques leverage various medical imaging modalities, including X-ray, CT, MRI, and ultrasound, to facilitate the identification of cancerous lesions. Traditional manual interpretation by radiologists is often subjective and time-consuming, highlighting the critical need for automated systems that enhance detection capabilities and reduce human error \cite{Istiak_2024}. 

This comprehensive review encompasses 12 types of cancer, analyzing 99 research articles published between 2020 and 2024. The study emphasizes the importance of early detection, which substantially increases the likelihood of successful treatment and prolonged survival. For instance, breast cancer, cervical cancer, and lung cancer are among the most prevalent types, necessitating effective screening strategies \cite{Istiak_2024}. The survey examines various cancer detection methods, including those that utilize deep learning for image preprocessing, segmentation, and feature extraction. 

Deep learning models, particularly convolutional neural networks (CNNs), have become a cornerstone in the analysis of medical images for cancer detection. These models excel in identifying patterns and anomalies within imaging data, thereby enhancing the accuracy of diagnoses. Techniques such as transfer learning further augment model performance, especially when working with limited datasets, ensuring that even smaller and less represented cancer types can be accurately detected \cite{Istiak_2024}. 

The review also addresses the challenges associated with medical imaging data, such as imbalanced datasets and the need for extensive annotated training data. The authors stress that while machine learning algorithms can process complex datasets effectively, the quality of input data is paramount for achieving reliable outcomes. Moreover, the integration of advanced image preprocessing techniques, such as filtering and augmentation, is highlighted as essential for improving image quality before analysis \cite{Istiak_2024}. 

In conclusion, the study identifies future directions for enhancing cancer detection methodologies. These include developing more robust and interpretable models, increasing data availability through collaboration, and employing advanced segmentation techniques that incorporate multi-modal imaging approaches. The integration of deep learning into clinical workflows promises to revolutionize cancer diagnosis and treatment, ultimately leading to better patient outcomes \cite{Istiak_2024}.
\section{Deep learning integration}
The extraction of features is a critical step in optimizing machine learning models for biological data analysis, particularly in the context of integrating genomic and histopathological data. The inherent complexity and heterogeneity of biological data necessitate a sophisticated approach to feature extraction that can bridge the gap between the molecular and phenotypic levels. The application of deep learning techniques, especially convolutional neural networks (CNNs), has emerged as a powerful method for automating the extraction of visual features from histopathological images, enabling a more objective and quantifiable assessment compared to traditional methods reliant on subjective evaluations by histopathologists \cite{Liviu_2020}.

Historically, the integration of genomic data with histopathological images has been limited by the challenges posed by each modality's unique characteristics. Genomic approaches offer insights into gene expression profiles, which are crucial for understanding the molecular underpinnings of diseases, while histopathological images provide essential context regarding tissue morphology and structure. By leveraging deep learning for feature extraction, researchers can correlate visual features with gene expression data, facilitating an understanding of how specific gene perturbations manifest in histological phenotypes \cite{Nam_2020}. This correlation is vital for elucidating the causal relationships between genes and their phenotypic expressions, which has been a long-standing challenge in biological research.

Moreover, the rich datasets available from initiatives like The Cancer Genome Atlas (TCGA) and the Genotype-Tissue Expression (GTEx) project provide an invaluable resource for training deep learning models. These datasets contain paired genomic and histological information, allowing for robust training of models that can predict and classify tissue types based on their visual characteristics. The use of transfer learning from existing neural network architectures trained on large image datasets (like ImageNet) can also enhance performance in histopathology by capturing fundamental visual features such as edges and textures, which are common across different types of images \cite{Liviu_2020}.

Feature extraction not only improves the accuracy and efficiency of machine learning models but also contributes to their interpretability. By visualizing the features learned by CNNs, researchers can gain insights into the biological significance of these features, linking them back to gene expression profiles. This enhances the understanding of the morphological aspects of tissues, providing a clearer picture of how genetic information translates into observable traits \cite{Nam_2020}. Such insights are essential for advancing personalized medicine, where understanding the unique biological makeup of individual patients can lead to more tailored treatments.

In conclusion, the combination of deep learning for feature extraction and multi-omics data integration represents a significant advancement in the analysis of biological systems. This approach not only enhances the predictive capabilities of machine learning models but also provides a pathway for deeper biological understanding, facilitating the discovery of novel relationships between genetic information and phenotypic expression.
\section{Trends of brain cancer deep learning}
The rapid advancement in deep learning and medical imaging technologies has significantly improved early cancer detection, which is crucial for effective treatment and better patient outcomes. Traditional methods of cancer diagnosis often rely on manual interpretation of imaging data by radiologists, which can be subjective and time-consuming. This has created a pressing need for automated systems that can enhance diagnostic accuracy and efficiency. Recent studies have underscored the importance of integrating artificial intelligence (AI) into medical imaging, particularly through Computer-Aided Diagnosis (CAD) systems. These systems utilize sophisticated algorithms to analyze medical images, thus facilitating early detection by minimizing human errors and processing vast amounts of data swiftly \cite{Istiak_2024}.

A comprehensive survey of various cancer detection methods reveals a wealth of research focusing on multiple cancer types, including breast, cervical, and lung cancers. The study highlights the critical role of deep learning techniques, especially convolutional neural networks (CNNs) and their variants, in improving detection rates. These methods enable the extraction of meaningful features from medical images, which is essential for accurate classification and diagnosis \cite{Istiak_2024}. Additionally, transfer learning has emerged as a powerful approach to enhance model performance, particularly in scenarios with limited annotated data. By leveraging pre-trained models, researchers can achieve higher accuracy and reliability in detecting cancerous lesions \cite{Istiak_2024}.

Despite these advances, the field still faces significant challenges, including data quality issues, the need for large and diverse datasets, and the complexities associated with model generalization and interpretability. Imbalanced datasets, where the number of non-cancerous images overwhelmingly outnumbers cancerous ones, can lead to biased models that perform poorly on minority classes \cite{Istiak_2024}. Furthermore, the interpretability of deep learning models remains a concern, as understanding the decision-making process of AI systems is crucial for clinical acceptance and trust. Researchers are actively exploring methods to provide clearer insights into how models arrive at their conclusions, which is vital for integrating AI into clinical workflows \cite{Istiak_2024}.

Future directions in cancer detection research must address these limitations by developing robust, interpretable models and enhancing data availability through collaborative efforts and advanced augmentation techniques. The integration of multi-modal imaging and advanced segmentation algorithms could further improve detection capabilities, allowing for more accurate and reliable cancer diagnostics. Ultimately, the ongoing evolution of AI in medical imaging holds the potential to revolutionize early cancer detection, leading to improved patient care and outcomes \cite{Istiak_2024}.
\section{Related works and original contributions of the paper}
Recent advancements in deep learning techniques have transformed the landscape of medical imaging, particularly in the context of brain tumor diagnosis and treatment planning. Vong et al. \cite{Chun_2025} present a systematic review highlighting the underutilization of machine learning (ML) and deep learning (DL) methodologies in glioblastoma (GBM) histopathological studies. Their analysis of 54 studies reveals a growing trend towards integrating histological and genomic data but underscores significant gaps in the clear reporting of methodologies. This sets the stage for future research to enhance the reliability and robustness of ML/DL applications in GBM research through better data integration and methodological transparency.

On the other hand, Gunasekaran et al. \cite{Subathra_2024} propose a hybrid deep learning model, ConvNet-ResNeXt101, specifically designed for automated brain tumor segmentation and classification from MRI images. Their approach emphasizes the importance of both feature extraction and advanced optimization techniques, achieving impressive classification accuracy of 99.27%, showcasing how deep learning can substantially improve diagnostic processes. This demonstrates the practical application of deep learning frameworks in overcoming traditional imaging challenges, thus positioning their research as a significant step toward automated brain tumor diagnostics.

In a broader context, Ahmad and Alqurashi \cite{Istiak_2024} conducted a comprehensive survey encompassing early cancer detection methods across various cancer types. Their review emphasizes the critical need for automated decision-making systems to enhance diagnostic accuracy, discuss diverse detection techniques, and address challenges such as data imbalance and model interpretability. By offering a systematic analysis of 99 studies, they provide valuable insights that can guide future research into developing more robust and reliable cancer detection methodologies utilizing ML and DL techniques.

Together, these contributions illustrate a pivotal moment in the integration of advanced computational techniques within medical imaging. By leveraging deep learning for effective tumor classification, enhancing data integration strategies, and addressing limitations in current methodologies, the field is poised for significant advancements in early detection and treatment planning. The findings suggest that a concerted effort to refine these technologies can lead to innovative solutions, ultimately improving patient outcomes and enriching clinical practices in oncology.

\begin{itemize}[label=\textbullet]
    \item User a machine learning-based methodology to select the most relevant papers, standing out the latest and most cited papers in the area.
    \item Provides a comprehensive survey on deep learning advancements in brain cancer detection, highlighting innovative models and methodologies that enhance diagnostic accuracy and patient outcomes.
    \item Fundamentals of Brain Cancer Deep Learning presents a novel deep learning model, FT-FEDTL, which significantly enhances brain tumor classification accuracy using microwave imaging data.
    \item Evaluation of Brain Cancer Deep Learning highlights the limited integration of machine learning with glioblastoma research, emphasizing the need for clearer methodologies and comprehensive data usage.
    \item Deep Learning Glioma introduces a new model that classifies gliomas directly from MRSI data, improving diagnostic efficiency by bypassing traditional preprocessing methods and enhancing accuracy.
    \item SLCA-UNet Advancement showcases an innovative architecture that improves brain tumor segmentation, combining advanced techniques to enhance accuracy and reduce processing time in medical imaging.
    \item Deep Learning Oncology emphasizes how deep learning is transforming cancer detection methodologies, improving diagnostic accuracy across various cancer types through automated analysis of medical images.
    \item Deep Learning Integration focuses on feature extraction through deep learning, bridging genomic and histopathological data for better understanding of disease mechanisms and personalized medicine.
    \item Trends of Brain Cancer Deep Learning explores the integration of AI in medical imaging, addressing the need for robust, interpretable models to enhance early cancer detection and patient outcomes.
\end{itemize}
\section{Conclusions}
The integration of deep learning techniques into brain cancer detection represents a transformative advancement in medical imaging, enhancing diagnostic accuracy and efficiency. This systematic review highlights key contributions, including the development of innovative models like FT	extendash{}FEDTL, which significantly improves tumor classification using microwave imaging data. Additionally, the proposed SLCA	extendash{}UNet architecture addresses limitations in traditional segmentation methods by incorporating advanced techniques that enhance accuracy while reducing processing time. Despite the promising advancements, challenges persist in the integration of machine learning with glioblastoma research, underscoring the need for clearer methodologies and comprehensive data utilization. The review emphasizes the importance of bridging genomic and histopathological data for a more profound understanding of disease mechanisms, paving the way for personalized medicine. Furthermore, it advocates for the development of robust and interpretable models that can facilitate automated analysis across various cancer types, ultimately improving patient outcomes. By refining these technologies and addressing existing limitations, the field of brain cancer detection is poised for significant advancements, fostering innovative solutions that enrich clinical practices in oncology and enhance early detection capabilities.
\begin{thebibliography}{00}
    \bibitem{Amran_2024} Amran Hossain and Rafiqul Islam and Mohammad Tariqul Islam and Phumin Kirawanich and Mohamed S. Soliman (2024). FT-FEDTL: A fine-tuned feature-extracted deep transfer learning model for multi-class microwave-based brain tumor classification.
\bibitem{Erin_2025} Erin B Bjrkeli; Knut Johannessen; Jonn Terje Geitung; Anna Karlberg; Live Eikenes; Morteza Esmaeili. (2025). Deep neural network modeling for brain tumor classification using magnetic resonance spectroscopic imaging. PLOS ONE: https://journals.plos.org/plosone/article?id=10.1371/journal.pdig.0000784
\bibitem{P.S._2025} P.S. Tejashwini and J. Thriveni and K.R. Venugopal (2025). A novel SLCA-UNet architecture for automatic MRI brain tumor segmentation.
\bibitem{Nam_2020} Nam D Nguyen; Daifeng Wang. (2020). Multiview learning for understanding functional multiomics. PLOS ONE: https://journals.plos.org/plosone/article?id=10.1371/journal.pcbi.1007677
\bibitem{Liviu_2020} Liviu Badea; Emil Stanescu. (2020). Identifying transcriptomic correlates of histology using deep learning. PLOS ONE: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0242858
\bibitem{Chun_2025} Chun Kiet Vong and Alan Wang and Mike Dragunow and Thomas I-H. Park and Vickie Shim (2025). Brain tumour histopathology through the lens of deep learning: A systematic review.
\bibitem{Istiak_2024} Istiak Ahmad and Fahad Alqurashi (2024). Early cancer detection using deep learning and medical imaging: A survey.
\bibitem{Subathra_2024} Subathra Gunasekaran; Prabin Selvestar Mercy Bai; Sandeep Kumar Mathivanan; Hariharan Rajadurai; Basu Dev Shivahare; Mohd Asif Shah. (2024). Automated brain tumor diagnostics: Empowering neuro-oncology with deep learning-based MRI image analysis. PLOS ONE: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0306493.
\bibitem{b1}
    Hurtado, Remigio; Picรยณn, Cristian; Muรยฑoz, Arantxa; Hurtado, Juan.
    "Survey of Intent-Based Networks and a Methodology Based on Machine Learning and Natural Language Processing."
    In Proceedings of Eighth International Congress on Information and Communication Technology.
    Springer Nature Singapore, Singapore, 2024.
    \bibitem{b2}
    Park, Keunheung; Kim, Jinmi; Lee, Jiwoong. 
    ``Visual Field Prediction using Recurrent Neural Network,'' 
    \emph{Scientific Reports}, 
    vol. 9, no. 1, p. 8385, 
    2019, 
    https://doi.org/10.1038/s41598-019-44852-6.
    
    \bibitem{b3}
    Xu, M.; Du, J.; Guan, Z.; Xue, Z.; Kou, F.; Shi, L.; Xu, X.; Li, A. 
    ``A Multi-RNN Research Topic Prediction Model Based on Spatial Attention and Semantic Consistency-Based Scientific Influence Modeling,'' 
    \emph{Comput Intell Neurosci}, 
    vol. 2021, 
    2021, 
    p. 1766743, 
    doi: 10.1155/2021/1766743.
    
    \bibitem{b4}
    Kreutz, Christin; Schenkel, Ralf.
    ``Scientific Paper Recommendation Systems: a Literature Review of recent Publications,''
    2022/01/03.
	\bibitem{Hurtado2023} Hurtado, R., et al. "Survey of Intent-Based Networks and a Methodology Based on Machine Learning and Natural Language Processing." International Congress on Information and Communication Technology. Singapore: Springer Nature Singapore, 2023.
    \bibitem{Lopez2024} Lopez, A., Dutan, D., Hurtado, R. "A New Method for Predicting the Importance of Scientific Articles on Topics of Interest Using Natural Language Processing and Recurrent Neural Networks." In: Yang, X.S., Sherratt, S., Dey, N., Joshi, A. (eds) Proceedings of Ninth International Congress on Information and Communication Technology. ICICT 2024 2024. Lecture Notes in Networks and Systems, vol 1013. Springer, Singapore. https://doi.org/10.1007/978-981-97-3559-4\_50.
\end{thebibliography}
\end{document}